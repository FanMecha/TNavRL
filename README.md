# TNavRL: Cross-Modal Transformer for Humanoid Visual Navigation
[![Python](https://img.shields.io/badge/python-3.10-4B8BBE.svg)](https://docs.python.org/3/whatsnew/3.10.html)
[![IsaacLab](https://img.shields.io/badge/IsaacLab-NVIDIA-C0392B.svg)](https://github.com/NVIDIA-Omniverse/IsaacLab)
[![Linux platform](https://img.shields.io/badge/platform-Ubuntu-27AE60.svg)](https://releases.ubuntu.com/22.04/)
[![C++](https://img.shields.io/badge/C++-17-00599C.svg)](https://en.cppreference.com/w/cpp/17)
[![ONNX Runtime](https://img.shields.io/badge/ONNX_Runtime-1.x-5C2D91.svg)](https://onnxruntime.ai/)

<p align="center">
  <a href="https://fanmecha.github.io/TNavRL/"><b>ðŸŽ¬ Demos</b></a>
  &nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;
  <b>ðŸ’» Code (coming soon)</b>
</p>

Welcome to the TNavRL repositoryï¼Œwhich was designed to enable humanoid robots to safely navigate cluttered environments using Reinforcement Learning. And it can be extended to any robot that adopts a velocity-based control system.





